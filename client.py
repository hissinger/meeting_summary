from openai import OpenAI
import os
import httpx
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# MCP Tool definition (like OpenAI's tools schema)
tools = [
    {
        "type": "function",
        "function": {
            "name": "generate_summary",
            "description": "íšŒì˜ ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ì•¡ì…˜ ì•„ì´í…œì„ ì •ë¦¬í•©ë‹ˆë‹¤.",
            "parameters": {
                "type": "object",
                "properties": {
                    "room_id": {
                        "type": "string",
                        "description": "ìš”ì•½í•  íšŒì˜ì˜ room ID"
                    }
                },
                "required": ["room_id"]
            }
        }
    }
]

# Function execution handling
def call_tool(tool_call):
    if tool_call.function.name == "generate_summary":
        args = eval(tool_call.function.arguments)  # or use json.loads()
        room_id = args["room_id"]
        response = httpx.post(
            "http://localhost:8000/summarize",
            json={"room_id": room_id},
            timeout=30.0  # wait up to 30 seconds
        )
        result = response.json()["summary"]["summary"]
        return {
            "tool_call_id": tool_call.id,
            "output": result
        }

# Send request to LLM
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "user", "content": "test-room íšŒì˜ ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ì•¡ì…˜ ì•„ì´í…œì„ ì•Œë ¤ì¤˜"}
    ],
    tools=tools,
    tool_choice="auto"
)

# Check if tool call is made
if response.choices[0].finish_reason == "tool_calls":
    tool_call = response.choices[0].message.tool_calls[0]
    tool_result = call_tool(tool_call)

    # Pass tool response to LLM to get final summary
    final = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "user", "content": "test-room íšŒì˜ ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ì•¡ì…˜ ì•„ì´í…œì„ ì•Œë ¤ì¤˜"},
            {
                "role": "assistant",
                "tool_calls": [tool_call]
            },
            {
                "role": "tool",
                "tool_call_id": tool_result["tool_call_id"],
                "content": tool_result["output"]
            }
        ]
    )
    print("ğŸ“‹ ìµœì¢… ìš”ì•½:\n", final.choices[0].message.content)
else:
    print("ğŸ”¹ ìš”ì•½ ê²°ê³¼:\n", response.choices[0].message.content)