from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain_core.tools import tool
from langchain.prompts import ChatPromptTemplate
import httpx

load_dotenv()

# MCP ë„êµ¬ ì •ì˜
@tool(description="íšŒì˜ ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ì•¡ì…˜ ì•„ì´í…œì„ ì •ë¦¬í•©ë‹ˆë‹¤.")
def generate_summary(room_id: str) -> str:
    response = httpx.post(
        "http://localhost:8000/summarize",
        json={"room_id": room_id},
        timeout=30.0
    )
    return response.json()["summary"]["summary"]

# LLM ì„¤ì •
llm = ChatOpenAI(model="gpt-4o-mini")

# í”„ë¡¬í”„íŠ¸ êµ¬ì„±
prompt = ChatPromptTemplate.from_messages([
    ("system", "ë‹¹ì‹ ì€ íšŒì˜ ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ì•¡ì…˜ ì•„ì´í…œì„ ì¶”ì¶œí•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."),
    ("user", "{input}"),
    ("assistant", "{agent_scratchpad}")
])

# LangChain ì—ì´ì „íŠ¸ ì„¤ì •
tools = [generate_summary]
agent = create_openai_functions_agent(
    llm=llm,
    tools=tools,
    prompt=prompt
)
executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

# ì‹¤í–‰
response = executor.invoke({"input": "test-room íšŒì˜ ë‚´ìš©ì„ ìš”ì•½í•˜ê³  ì•¡ì…˜ ì•„ì´í…œì„ ì•Œë ¤ì¤˜"})
print("ğŸ“‹ ìµœì¢… ìš”ì•½:\n", response["output"])